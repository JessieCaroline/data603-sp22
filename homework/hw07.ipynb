{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1sjS06Vf0Zg"
      },
      "outputs": [],
      "source": [
        "import pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJqG8XoQf04E"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.getOrCreate()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJSJM_DMOARS"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaAlVR-XHu0J"
      },
      "outputs": [],
      "source": [
        "cschema = StructType([\n",
        "StructField('Date',StringType(), True),\n",
        "StructField('Location',StringType(), True),\n",
        "StructField('MinTemp',FloatType(), True),\n",
        "StructField('MaxTemp',FloatType(), True),\n",
        "StructField('Rainfall',FloatType(), True),\n",
        "StructField('Evaporation',FloatType(), True),\n",
        "StructField('Sunshine',FloatType(), True),\n",
        "StructField('WindGustDir',StringType(), True),\n",
        "StructField('WindGustSpeed',IntegerType(), True),\n",
        "StructField('WindDir9am',StringType(), True),\n",
        "StructField('WindDir3pm',StringType(), True),\n",
        "StructField('WindSpeed9am',IntegerType(), True),\n",
        "StructField('WindSpeed3pm',IntegerType(), True),\n",
        "StructField('Humidity9am',IntegerType(), True),\n",
        "StructField('Humidity3pm',IntegerType(), True),\n",
        "StructField('Pressure9am',FloatType(), True),\n",
        "StructField('Pressure3pm',FloatType(), True),\n",
        "StructField('Cloud9am',IntegerType(), True),\n",
        "StructField('Cloud3pm',IntegerType(), True),\n",
        "StructField('Temp9am',FloatType(), True),\n",
        "StructField('Temp3pm',FloatType(), True),\n",
        "StructField('RainToday',StringType(), True),\n",
        "StructField('RainTomorrow',StringType(), True)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jqzf-BAAawec"
      },
      "outputs": [],
      "source": [
        "df = spark.read.csv('weatherAUS.csv', header=True, schema=cschema)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuU2SbgTbylC",
        "outputId": "b7777398-189f-413e-a4b4-801665b7fce6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------+-------+-------+--------+-----------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+--------+--------+-------+-------+---------+------------+\n",
            "|      Date|Location|MinTemp|MaxTemp|Rainfall|Evaporation|Sunshine|WindGustDir|WindGustSpeed|WindDir9am|WindDir3pm|WindSpeed9am|WindSpeed3pm|Humidity9am|Humidity3pm|Pressure9am|Pressure3pm|Cloud9am|Cloud3pm|Temp9am|Temp3pm|RainToday|RainTomorrow|\n",
            "+----------+--------+-------+-------+--------+-----------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+--------+--------+-------+-------+---------+------------+\n",
            "|2008-12-01|  Albury|   13.4|   22.9|     0.6|       null|    null|          W|           44|         W|       WNW|          20|          24|         71|         22|     1007.7|     1007.1|       8|    null|   16.9|   21.8|       No|          No|\n",
            "|2008-12-02|  Albury|    7.4|   25.1|     0.0|       null|    null|        WNW|           44|       NNW|       WSW|           4|          22|         44|         25|     1010.6|     1007.8|    null|    null|   17.2|   24.3|       No|          No|\n",
            "|2008-12-03|  Albury|   12.9|   25.7|     0.0|       null|    null|        WSW|           46|         W|       WSW|          19|          26|         38|         30|     1007.6|     1008.7|    null|       2|   21.0|   23.2|       No|          No|\n",
            "|2008-12-04|  Albury|    9.2|   28.0|     0.0|       null|    null|         NE|           24|        SE|         E|          11|           9|         45|         16|     1017.6|     1012.8|    null|    null|   18.1|   26.5|       No|          No|\n",
            "|2008-12-05|  Albury|   17.5|   32.3|     1.0|       null|    null|          W|           41|       ENE|        NW|           7|          20|         82|         33|     1010.8|     1006.0|       7|       8|   17.8|   29.7|       No|          No|\n",
            "+----------+--------+-------+-------+--------+-----------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+--------+--------+-------+-------+---------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpmAHJ02cnTF",
        "outputId": "c909ab2f-3edc-4c3a-ab75-07a7f0c59536"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Date: string (nullable = true)\n",
            " |-- Location: string (nullable = true)\n",
            " |-- MinTemp: float (nullable = true)\n",
            " |-- MaxTemp: float (nullable = true)\n",
            " |-- Rainfall: float (nullable = true)\n",
            " |-- Evaporation: float (nullable = true)\n",
            " |-- Sunshine: float (nullable = true)\n",
            " |-- WindGustDir: string (nullable = true)\n",
            " |-- WindGustSpeed: integer (nullable = true)\n",
            " |-- WindDir9am: string (nullable = true)\n",
            " |-- WindDir3pm: string (nullable = true)\n",
            " |-- WindSpeed9am: integer (nullable = true)\n",
            " |-- WindSpeed3pm: integer (nullable = true)\n",
            " |-- Humidity9am: integer (nullable = true)\n",
            " |-- Humidity3pm: integer (nullable = true)\n",
            " |-- Pressure9am: float (nullable = true)\n",
            " |-- Pressure3pm: float (nullable = true)\n",
            " |-- Cloud9am: integer (nullable = true)\n",
            " |-- Cloud3pm: integer (nullable = true)\n",
            " |-- Temp9am: float (nullable = true)\n",
            " |-- Temp3pm: float (nullable = true)\n",
            " |-- RainToday: string (nullable = true)\n",
            " |-- RainTomorrow: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0y-ujZvcsP2"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit, CrossValidator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xidqFQQ1JJsC"
      },
      "outputs": [],
      "source": [
        "from pyspark.mllib.tree import DecisionTree, DecisionTreeModel\n",
        "from pyspark.mllib.util import MLUtils\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REFEwifrG62N"
      },
      "outputs": [],
      "source": [
        "(trainingData, testData) =df.randomSplit([0.8, 0.2],12345)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byk22l_xPQEx",
        "outputId": "633a1dba-4090-41b0-8a5c-8912ebc76cf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------+-------+-------+--------+-----------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+--------+--------+-------+-------+---------+------------+\n",
            "|Date|Location|MinTemp|MaxTemp|Rainfall|Evaporation|Sunshine|WindGustDir|WindGustSpeed|WindDir9am|WindDir3pm|WindSpeed9am|WindSpeed3pm|Humidity9am|Humidity3pm|Pressure9am|Pressure3pm|Cloud9am|Cloud3pm|Temp9am|Temp3pm|RainToday|RainTomorrow|\n",
            "+----+--------+-------+-------+--------+-----------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+--------+--------+-------+-------+---------+------------+\n",
            "|   0|       0|      0|      0|       0|          0|       0|          0|            0|         0|         0|           0|           0|          0|          0|          0|          0|       0|       0|      0|      0|        0|           0|\n",
            "+----+--------+-------+-------+--------+-----------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+--------+--------+-------+-------+---------+------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#https://www.datasciencemadesimple.com/count-of-missing-nanna-and-null-values-in-pyspark/\n",
        "df.select([count(when(isnan(c), c)).alias(c) for c in df.columns]).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYFuiZZjT361",
        "outputId": "01953da7-9737-483f-f15b-5dd505f87192"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------+-------+-------+--------+-----------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+--------+--------+-------+-------+---------+------------+\n",
            "|Date|Location|MinTemp|MaxTemp|Rainfall|Evaporation|Sunshine|WindGustDir|WindGustSpeed|WindDir9am|WindDir3pm|WindSpeed9am|WindSpeed3pm|Humidity9am|Humidity3pm|Pressure9am|Pressure3pm|Cloud9am|Cloud3pm|Temp9am|Temp3pm|RainToday|RainTomorrow|\n",
            "+----+--------+-------+-------+--------+-----------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+--------+--------+-------+-------+---------+------------+\n",
            "|   0|       0|   1485|   1261|    3261|      62790|   69835|          0|        10263|         0|         0|        1767|        3062|       2654|       4507|      15065|      15028|   55888|   59358|   1767|   3609|        0|           0|\n",
            "+----+--------+-------+-------+--------+-----------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+--------+--------+-------+-------+---------+------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.select([count(when(isnull(c), c)).alias(c) for c in df.columns]).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92eoKFzWat0x"
      },
      "source": [
        "Dropping the columns Sunshine and Evaporation as they have high number of null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwbmWB5Ta8M7"
      },
      "outputs": [],
      "source": [
        "df  = df.drop(\"Evaporation\", \"Sunshine\",\"Cloud9am\",\"Cloud3pm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mkx_rN7zdCp6"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import Imputer,OneHotEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zOcG16lbGBN"
      },
      "outputs": [],
      "source": [
        "imputer = Imputer(inputCols=[\"MinTemp\", \"MaxTemp\",\"Rainfall\",\"WindGustSpeed\",\"WindSpeed9am\",\"WindSpeed3pm\",\n",
        "                             \"Humidity9am\",\"Humidity3pm\",\"Pressure9am\",\"Pressure3pm\",\"Temp9am\",\"Temp3pm\"],outputCols=[\"OutMinTemp\", \"OutMaxTemp\",\"OutRainfall\",\"OutWindGustSpeed\",\"OutWindSpeed9am\",\"OutWindSpeed3pm\",\n",
        "                             \"Humidity9am\",\"OutHumidity3pm\",\"OutPressure9am\",\"OutPressure3pm\",\"OutTemp9am\",\"OutTemp3pm\"])\n",
        "model = imputer.fit(df)\n",
        "\n",
        "df=model.transform(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select([count(when(isnull(c), c)).alias(c) for c in df.columns]).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjSP-mPf-8U7",
        "outputId": "1f10ed01-1742-4ba4-8ee8-55f074f9f79a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+-------+-------+---------+------------+----------+----------+-----------+----------------+---------------+---------------+--------------+--------------+--------------+----------+----------+\n",
            "|Date|Location|MinTemp|MaxTemp|Rainfall|WindGustDir|WindGustSpeed|WindDir9am|WindDir3pm|WindSpeed9am|WindSpeed3pm|Humidity9am|Humidity3pm|Pressure9am|Pressure3pm|Temp9am|Temp3pm|RainToday|RainTomorrow|OutMinTemp|OutMaxTemp|OutRainfall|OutWindGustSpeed|OutWindSpeed9am|OutWindSpeed3pm|OutHumidity3pm|OutPressure9am|OutPressure3pm|OutTemp9am|OutTemp3pm|\n",
            "+----+--------+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+-------+-------+---------+------------+----------+----------+-----------+----------------+---------------+---------------+--------------+--------------+--------------+----------+----------+\n",
            "|   0|       0|   1485|   1261|    3261|          0|        10263|         0|         0|        1767|        3062|          0|       4507|      15065|      15028|   1767|   3609|        0|           0|         0|         0|          0|               0|              0|              0|             0|             0|             0|         0|         0|\n",
            "+----+--------+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+-------+-------+---------+------------+----------+----------+-----------+----------------+---------------+---------------+--------------+--------------+--------------+----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdHjl90adBoK"
      },
      "outputs": [],
      "source": [
        "stage1 = StringIndexer(inputCol=\"Date\", outputCol=\"indexeddate\").fit(df)\n",
        "stage2 = StringIndexer(inputCol=\"Location\",outputCol=\"indexedlocation\").fit(df)\n",
        "stage3 = StringIndexer(inputCol=\"WindGustDir\",outputCol=\"indexedWindGustDir\").fit(df)\n",
        "stage4 = StringIndexer(inputCol=\"WindDir9am\",outputCol=\"indexedWindDir9am\").fit(df)\n",
        "stage5 = StringIndexer(inputCol=\"WindDir3pm\",outputCol=\"indexedWindDir3pm\").fit(df)\n",
        "stage6 = StringIndexer(inputCol=\"RainToday\",outputCol=\"indexedRainToday\").fit(df)\n",
        "\n",
        "df = stage1.transform(df)\n",
        "df = stage2.transform(df)\n",
        "df = stage3.transform(df)\n",
        "df = stage4.transform(df)\n",
        "df = stage5.transform(df)\n",
        "df = stage6.transform(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql.functions as F\n",
        "import pyspark.sql.types as T\n"
      ],
      "metadata": {
        "id": "mbGaOXqZAFqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn(\"WindGustDir\",F.when(F.col(\"WindGustDir\") == 'NA','W').otherwise(F.col(\"WindGustDir\")))\n",
        "df = df.withColumn(\"WindDir9am\",F.when(F.col(\"WindDir9am\") == 'NA','N').otherwise(F.col(\"WindDir9am\")))\n",
        "df = df.withColumn(\"WindDir3pm\",F.when(F.col(\"WindDir3pm\") == 'NA','SE').otherwise(F.col(\"WindDir3pm\")))\n",
        "df = df.withColumn(\"RainToday\",F.when(F.col(\"RainToday\") == 'NA','No').otherwise(F.col(\"RainToday\")))\n",
        "df = df.withColumn(\"RainTomorrow\",F.when(F.col(\"RainTomorrow\") == 'NA','No').otherwise(F.col(\"RainTomorrow\")))"
      ],
      "metadata": {
        "id": "6Xyevarn_xAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50Vgrq42Mxlo"
      },
      "outputs": [],
      "source": [
        "label_index = StringIndexer(inputCol=\"RainTomorrow\",outputCol=\"label\")\n",
        "df = label_index.fit(df).transform(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ERsIbbEe2gM"
      },
      "outputs": [],
      "source": [
        "OHE = OneHotEncoder(inputCols=[\"indexeddate\",\"indexedlocation\",\"indexedWindGustDir\",\"indexedWindDir9am\",\"indexedWindDir3pm\",\"indexedRainToday\"],\n",
        "                         outputCols=[\"encodeddate\",\"encodedlocation\",\"encodedwindgust\",\"encodedWindDir9am\",\"encodedWindDir3pm\",\"encodedRainToday\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EnWN4zWLELZ"
      },
      "outputs": [],
      "source": [
        "df = OHE.fit(df).transform(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZ2-zyG5LJel"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import VectorAssembler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3g9nylfCLOLD",
        "outputId": "bb03f704-f0cc-45d1-9c57-d602ee5ccb7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+-------+-------+---------+------------+----------+----------+-----------+----------------+---------------+---------------+--------------+--------------+--------------+----------+----------+-----------+---------------+------------------+-----------------+-----------------+----------------+-----+-------------------+---------------+---------------+-----------------+-----------------+----------------+\n",
            "|      Date|Location|MinTemp|MaxTemp|Rainfall|WindGustDir|WindGustSpeed|WindDir9am|WindDir3pm|WindSpeed9am|WindSpeed3pm|Humidity9am|Humidity3pm|Pressure9am|Pressure3pm|Temp9am|Temp3pm|RainToday|RainTomorrow|OutMinTemp|OutMaxTemp|OutRainfall|OutWindGustSpeed|OutWindSpeed9am|OutWindSpeed3pm|OutHumidity3pm|OutPressure9am|OutPressure3pm|OutTemp9am|OutTemp3pm|indexeddate|indexedlocation|indexedWindGustDir|indexedWindDir9am|indexedWindDir3pm|indexedRainToday|label|        encodeddate|encodedlocation|encodedwindgust|encodedWindDir9am|encodedWindDir3pm|encodedRainToday|\n",
            "+----------+--------+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+-------+-------+---------+------------+----------+----------+-----------+----------------+---------------+---------------+--------------+--------------+--------------+----------+----------+-----------+---------------+------------------+-----------------+-----------------+----------------+-----+-------------------+---------------+---------------+-----------------+-----------------+----------------+\n",
            "|2008-12-01|  Albury|   13.4|   22.9|     0.6|          W|           44|         W|       WNW|          20|          24|         71|         22|     1007.7|     1007.1|   16.9|   21.8|       No|          No|      13.4|      22.9|        0.6|              44|             20|             24|            22|        1007.7|        1007.1|      16.9|      21.8|     3009.0|            9.0|               1.0|              7.0|              7.0|             0.0|  0.0|(3435,[3009],[1.0])| (48,[9],[1.0])| (16,[1],[1.0])|   (16,[7],[1.0])|   (16,[7],[1.0])|   (2,[0],[1.0])|\n",
            "|2008-12-02|  Albury|    7.4|   25.1|     0.0|        WNW|           44|       NNW|       WSW|           4|          22|         44|         25|     1010.6|     1007.8|   17.2|   24.3|       No|          No|       7.4|      25.1|        0.0|              44|              4|             22|            25|        1010.6|        1007.8|      17.2|      24.3|     3010.0|            9.0|              10.0|             10.0|              3.0|             0.0|  0.0|(3435,[3010],[1.0])| (48,[9],[1.0])|(16,[10],[1.0])|  (16,[10],[1.0])|   (16,[3],[1.0])|   (2,[0],[1.0])|\n",
            "|2008-12-03|  Albury|   12.9|   25.7|     0.0|        WSW|           46|         W|       WSW|          19|          26|         38|         30|     1007.6|     1008.7|   21.0|   23.2|       No|          No|      12.9|      25.7|        0.0|              46|             19|             26|            30|        1007.6|        1008.7|      21.0|      23.2|     3011.0|            9.0|               7.0|              7.0|              3.0|             0.0|  0.0|(3435,[3011],[1.0])| (48,[9],[1.0])| (16,[7],[1.0])|   (16,[7],[1.0])|   (16,[3],[1.0])|   (2,[0],[1.0])|\n",
            "|2008-12-04|  Albury|    9.2|   28.0|     0.0|         NE|           24|        SE|         E|          11|           9|         45|         16|     1017.6|     1012.8|   18.1|   26.5|       No|          No|       9.2|      28.0|        0.0|              24|             11|              9|            16|        1017.6|        1012.8|      18.1|      26.5|     3012.0|            9.0|              14.0|              2.0|             10.0|             0.0|  0.0|(3435,[3012],[1.0])| (48,[9],[1.0])|(16,[14],[1.0])|   (16,[2],[1.0])|  (16,[10],[1.0])|   (2,[0],[1.0])|\n",
            "|2008-12-05|  Albury|   17.5|   32.3|     1.0|          W|           41|       ENE|        NW|           7|          20|         82|         33|     1010.8|     1006.0|   17.8|   29.7|       No|          No|      17.5|      32.3|        1.0|              41|              7|             20|            33|        1010.8|        1006.0|      17.8|      29.7|     3013.0|            9.0|               1.0|             11.0|              8.0|             0.0|  0.0|(3435,[3013],[1.0])| (48,[9],[1.0])| (16,[1],[1.0])|  (16,[11],[1.0])|   (16,[8],[1.0])|   (2,[0],[1.0])|\n",
            "+----------+--------+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+-------+-------+---------+------------+----------+----------+-----------+----------------+---------------+---------------+--------------+--------------+--------------+----------+----------+-----------+---------------+------------------+-----------------+-----------------+----------------+-----+-------------------+---------------+---------------+-----------------+-----------------+----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2b8G9d44cH6T"
      },
      "outputs": [],
      "source": [
        "assembler = VectorAssembler(inputCols = ['OutMinTemp',\n",
        " 'OutMaxTemp',\n",
        " 'OutRainfall',\n",
        " 'OutWindGustSpeed',\n",
        " 'OutWindSpeed9am',\n",
        " 'OutWindSpeed3pm',\n",
        " 'OutHumidity3pm',\n",
        " 'OutPressure9am',\n",
        " 'OutPressure3pm',\n",
        " 'OutTemp9am',\n",
        " 'OutTemp3pm',\"encodeddate\",\"encodedlocation\",\"encodedwindgust\",\"encodedWindDir9am\",\"encodedWindDir3pm\",\"encodedRainToday\"], outputCol = \"features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiRa0CVic1D8"
      },
      "outputs": [],
      "source": [
        "df = assembler.transform(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uen6J8Jc5Rj",
        "outputId": "1aef302f-869e-4ad0-fd87-204d8bba410e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+-------+-------+---------+------------+----------+----------+-----------+----------------+---------------+---------------+--------------+--------------+--------------+----------+----------+-----------+---------------+------------------+-----------------+-----------------+----------------+-----+-------------------+---------------+---------------+-----------------+-----------------+----------------+--------------------+\n",
            "|      Date|Location|MinTemp|MaxTemp|Rainfall|WindGustDir|WindGustSpeed|WindDir9am|WindDir3pm|WindSpeed9am|WindSpeed3pm|Humidity9am|Humidity3pm|Pressure9am|Pressure3pm|Temp9am|Temp3pm|RainToday|RainTomorrow|OutMinTemp|OutMaxTemp|OutRainfall|OutWindGustSpeed|OutWindSpeed9am|OutWindSpeed3pm|OutHumidity3pm|OutPressure9am|OutPressure3pm|OutTemp9am|OutTemp3pm|indexeddate|indexedlocation|indexedWindGustDir|indexedWindDir9am|indexedWindDir3pm|indexedRainToday|label|        encodeddate|encodedlocation|encodedwindgust|encodedWindDir9am|encodedWindDir3pm|encodedRainToday|            features|\n",
            "+----------+--------+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+-------+-------+---------+------------+----------+----------+-----------+----------------+---------------+---------------+--------------+--------------+--------------+----------+----------+-----------+---------------+------------------+-----------------+-----------------+----------------+-----+-------------------+---------------+---------------+-----------------+-----------------+----------------+--------------------+\n",
            "|2008-12-01|  Albury|   13.4|   22.9|     0.6|          W|           44|         W|       WNW|          20|          24|         71|         22|     1007.7|     1007.1|   16.9|   21.8|       No|          No|      13.4|      22.9|        0.6|              44|             20|             24|            22|        1007.7|        1007.1|      16.9|      21.8|     3009.0|            9.0|               1.0|              7.0|              7.0|             0.0|  0.0|(3435,[3009],[1.0])| (48,[9],[1.0])| (16,[1],[1.0])|   (16,[7],[1.0])|   (16,[7],[1.0])|   (2,[0],[1.0])|(3544,[0,1,2,3,4,...|\n",
            "|2008-12-02|  Albury|    7.4|   25.1|     0.0|        WNW|           44|       NNW|       WSW|           4|          22|         44|         25|     1010.6|     1007.8|   17.2|   24.3|       No|          No|       7.4|      25.1|        0.0|              44|              4|             22|            25|        1010.6|        1007.8|      17.2|      24.3|     3010.0|            9.0|              10.0|             10.0|              3.0|             0.0|  0.0|(3435,[3010],[1.0])| (48,[9],[1.0])|(16,[10],[1.0])|  (16,[10],[1.0])|   (16,[3],[1.0])|   (2,[0],[1.0])|(3544,[0,1,3,4,5,...|\n",
            "|2008-12-03|  Albury|   12.9|   25.7|     0.0|        WSW|           46|         W|       WSW|          19|          26|         38|         30|     1007.6|     1008.7|   21.0|   23.2|       No|          No|      12.9|      25.7|        0.0|              46|             19|             26|            30|        1007.6|        1008.7|      21.0|      23.2|     3011.0|            9.0|               7.0|              7.0|              3.0|             0.0|  0.0|(3435,[3011],[1.0])| (48,[9],[1.0])| (16,[7],[1.0])|   (16,[7],[1.0])|   (16,[3],[1.0])|   (2,[0],[1.0])|(3544,[0,1,3,4,5,...|\n",
            "|2008-12-04|  Albury|    9.2|   28.0|     0.0|         NE|           24|        SE|         E|          11|           9|         45|         16|     1017.6|     1012.8|   18.1|   26.5|       No|          No|       9.2|      28.0|        0.0|              24|             11|              9|            16|        1017.6|        1012.8|      18.1|      26.5|     3012.0|            9.0|              14.0|              2.0|             10.0|             0.0|  0.0|(3435,[3012],[1.0])| (48,[9],[1.0])|(16,[14],[1.0])|   (16,[2],[1.0])|  (16,[10],[1.0])|   (2,[0],[1.0])|(3544,[0,1,3,4,5,...|\n",
            "|2008-12-05|  Albury|   17.5|   32.3|     1.0|          W|           41|       ENE|        NW|           7|          20|         82|         33|     1010.8|     1006.0|   17.8|   29.7|       No|          No|      17.5|      32.3|        1.0|              41|              7|             20|            33|        1010.8|        1006.0|      17.8|      29.7|     3013.0|            9.0|               1.0|             11.0|              8.0|             0.0|  0.0|(3435,[3013],[1.0])| (48,[9],[1.0])| (16,[1],[1.0])|  (16,[11],[1.0])|   (16,[8],[1.0])|   (2,[0],[1.0])|(3544,[0,1,2,3,4,...|\n",
            "+----------+--------+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+-------+-------+---------+------------+----------+----------+-----------+----------------+---------------+---------------+--------------+--------------+--------------+----------+----------+-----------+---------------+------------------+-----------------+-----------------+----------------+-----+-------------------+---------------+---------------+-----------------+-----------------+----------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKIGqUmwktJC"
      },
      "outputs": [],
      "source": [
        "(trainingData, testData) =df.randomSplit([0.8, 0.2],12345)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "0M9kzBd5ilKM"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "\n",
        "# Create initial Decision Tree Model\n",
        "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\",maxDepth=3)\n",
        "\n",
        "# Train model with Training Data\n",
        "dtModel = dt.fit(trainingData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "L0a_rk3RklAq"
      },
      "outputs": [],
      "source": [
        "predictions = dtModel.transform(testData)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "WYEo4Z9-mIoP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cdee22c-e5f4-4f04-a97c-0b45c5c0fba6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+--------------------+--------+---------+\n",
            "|label|prediction|         probability|Location|RainToday|\n",
            "+-----+----------+--------------------+--------+---------+\n",
            "|  0.0|       0.0|[0.85673122440158...|Canberra|       No|\n",
            "|  0.0|       0.0|[0.85673122440158...|Canberra|       No|\n",
            "|  0.0|       0.0|[0.85673122440158...|Canberra|       No|\n",
            "|  1.0|       0.0|[0.85673122440158...|Canberra|       No|\n",
            "|  1.0|       0.0|[0.61169987282746...|Canberra|       No|\n",
            "+-----+----------+--------------------+--------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "selected = predictions.select(\"label\", \"prediction\", \"probability\", \"Location\", \"RainToday\")\n",
        "selected.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dtparamGrid = (ParamGridBuilder()\n",
        "               .addGrid(dt.impurity, [\"gini\",\"entropy\"])\n",
        "             .addGrid(dt.maxDepth, [5])\n",
        "             .addGrid(dt.maxBins, [5, 10, 15])\n",
        "             .addGrid(dt.minInfoGain, [0.0, 0.2, 0.4])\n",
        "             .build())"
      ],
      "metadata": {
        "id": "vHGSEGNkCTs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.mllib.evaluation import BinaryClassificationMetrics"
      ],
      "metadata": {
        "id": "9nSbiG3oCbIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt = DecisionTreeClassifier(labelCol='label' , featuresCol=\"features\")"
      ],
      "metadata": {
        "id": "rTcx9-CpCcQO"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtevaluator = BinaryClassificationEvaluator().setLabelCol(\"label\")"
      ],
      "metadata": {
        "id": "BxeEmJMHCs-0"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv = CrossValidator(estimator = dt,\n",
        "                      estimatorParamMaps = dtparamGrid,\n",
        "                      evaluator = dtevaluator,\n",
        "                      numFolds = 4)"
      ],
      "metadata": {
        "id": "NAsTRWU-CwOq"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stages=[cv]"
      ],
      "metadata": {
        "id": "fxc-R7diEYu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline(stages=[OHE,cv])"
      ],
      "metadata": {
        "id": "qPKpi2fFDeSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipelinemodel = pipeline.fit(trainingData)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "dt8GetqeD2f1",
        "outputId": "2d6e90a0-1a7a-4dea-cda1-63598e79d82a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IllegalArgumentException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-391dffdb02f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipelinemodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             raise TypeError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/ml/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# must be an Estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m                     \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mindexOfLastEstimator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             raise TypeError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \"\"\"\n\u001b[1;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1322\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIllegalArgumentException\u001b[0m: requirement failed: Column encodeddate already exists."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUYzFWJ901Aj"
      },
      "outputs": [],
      "source": [
        "print('Decision Tree Accuracy (gini):', gini_ac.evaluate(dt_predictions))\n",
        "print('Decision Tree F1 (gini):', gini_f1.evaluate(dt_predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5X8nfzJ3Vpx"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "evaluator = MulticlassClassificationEvaluator()\n",
        "evaluator.evaluate(predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdSB9c3pXlNG"
      },
      "outputs": [],
      "source": [
        "#from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "#evaluator = BinaryClassificationEvaluator()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Pc6hhlb7QRp"
      },
      "outputs": [],
      "source": [
        "#predictions = cvModel.transform(testData)\n",
        "#evaluator.evaluate(predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4NLYR9z-6z8"
      },
      "outputs": [],
      "source": [
        "#predictionAndLabels = testData.map(lambda lp: (float(cvModel.predict(lp.features)), lp.label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yg7Ef53I47af"
      },
      "outputs": [],
      "source": [
        "cv1 = CrossValidator(estimator=dt, estimatorParamMaps=paramGrid1, evaluator=evaluator, numFolds=4)\n",
        "\n",
        "# Run cross validations\n",
        "cvModel1 = cv1.fit(trainingData)\n",
        "predictions1 = cvModel1.transform(testData)\n",
        "evaluator.evaluate(predictions1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sCyYFoV9_Mr"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline(stages=[label_index, assembler, dt,dt1,cv])\n",
        "model1 = pipeline.fit(trainingData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCF0T702-UTZ"
      },
      "outputs": [],
      "source": [
        "out_df = model.transform(testData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXEod8Uf-Xv1"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "hw07.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}